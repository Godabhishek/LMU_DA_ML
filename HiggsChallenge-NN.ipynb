{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgs Challenge Example using Neural Networks\n",
    "In this part we will look at the **[Higgs Boson ML Challenge](https://www.kaggle.com/c/Higgs-boson)** on Kaggle and attempt a solution using neural networks (NN). The data is available from **[CERN Open Data](http://opendata.cern.ch/record/328)**. More information about the data is available from the links, and in particular at **[Documentation](http://opendata.cern.ch/record/329/files/atlas-higgs-challenge-2014.pdf)**. The general idea is that we want to extract $H\\to\\tau\\tau$ signal from background. In particular, the selection requires one of the taus to decay into an electron or muon and two neutrinos, and the other into hadrons and a neutrino. The challenge is based on Monte Carlo events processed through the **[ATLAS detector](http://atlas.cern/)** simulation and reconstruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on [Neutral Networks][1].\n",
    "\n",
    "[1]: NN_Activation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start trying to apply a NN to the Higgs Challenge data. We will start using Scikit Learn, and then try **[Keras](https://keras.io/)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the usual setup: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "df = pd.read_csv('data/atlas-higgs-challenge-2014-v2.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "      <th>KaggleSet</th>\n",
       "      <th>KaggleWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>...</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.681042</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>2.233584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "      <td>0.715742</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>2.347389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.660654</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>5.446378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.904263</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>6.245333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0   100000       138.470                       51.655        97.827    27.980   \n",
       "1   100001       160.937                       68.768       103.235    48.146   \n",
       "2   100002      -999.000                      162.172       125.953    35.635   \n",
       "3   100003       143.905                       81.417        80.943     0.414   \n",
       "4   100004       175.864                       16.915       134.805    16.405   \n",
       "\n",
       "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                  0.91           124.711                2.666   \n",
       "1               -999.00          -999.000             -999.000   \n",
       "2               -999.00          -999.000             -999.000   \n",
       "3               -999.00          -999.000             -999.000   \n",
       "4               -999.00          -999.000             -999.000   \n",
       "\n",
       "   DER_deltar_tau_lep  DER_pt_tot      ...       PRI_jet_leading_eta  \\\n",
       "0               3.064      41.928      ...                     2.150   \n",
       "1               3.473       2.078      ...                     0.725   \n",
       "2               3.148       9.336      ...                     2.053   \n",
       "3               3.310       0.414      ...                  -999.000   \n",
       "4               3.891      16.405      ...                  -999.000   \n",
       "\n",
       "   PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                0.444                 46.062                    1.24   \n",
       "1                1.158               -999.000                 -999.00   \n",
       "2               -2.028               -999.000                 -999.00   \n",
       "3             -999.000               -999.000                 -999.00   \n",
       "4             -999.000               -999.000                 -999.00   \n",
       "\n",
       "   PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  Label  KaggleSet  \\\n",
       "0                  -2.475         113.497  0.000814      s          t   \n",
       "1                -999.000          46.226  0.681042      b          t   \n",
       "2                -999.000          44.251  0.715742      b          t   \n",
       "3                -999.000          -0.000  1.660654      b          t   \n",
       "4                -999.000           0.000  1.904263      b          t   \n",
       "\n",
       "   KaggleWeight  \n",
       "0      0.002653  \n",
       "1      2.233584  \n",
       "2      2.347389  \n",
       "3      5.446378  \n",
       "4      6.245333  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f57a0a2a150>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.PRI_jet_leading_pt[df.PRI_jet_leading_pt>0].hist(bins=50)\n",
    "plt.yscale('log')\n",
    "\n",
    "f=plt.figure()\n",
    "df.DER_mass_MMC[(df.DER_mass_MMC>0)&(df.DER_mass_MMC<250)].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is more information about the variables in the documentation. The variables that start with **DER** are derived quantities, determined by the physicists performing the analysis as variables that discriminate signal from backround. On the other hand, those that start with **PRI** are considered to be primary variables, from which the derived variables are calculated. They themselves generally do not provide much discrimination, but one if the ideas suggested by deep networks is that they can determine the necessary features from the primary variables, potentially even finding variables that the physicists did not consider. *EventId* identifies the event but is not a \"feature.\" The *Weight* is the event weight so that the sum of weights of all signal events should produce the signal yield expected to be observed in 2012, and the sum of weights of all background events should produce the backgroudn yield. Note that the weight varies event to event, because different background and signal processes contribute to the background and signal sets. *Label* indicates if it is a signal or background event. Ignore the *Kaggle* variables--they are only used if you want to reproduce exactly what was used in the Challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "      <th>KaggleSet</th>\n",
       "      <th>KaggleWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.910</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>...</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.681042</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.233584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "      <td>0.715742</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.347389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.660654</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.446378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.904263</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>6.245333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100005</td>\n",
       "      <td>89.744</td>\n",
       "      <td>13.550</td>\n",
       "      <td>59.149</td>\n",
       "      <td>116.344</td>\n",
       "      <td>2.636</td>\n",
       "      <td>284.584</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>1.362</td>\n",
       "      <td>61.619</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.412</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>56.165</td>\n",
       "      <td>0.224</td>\n",
       "      <td>3.106</td>\n",
       "      <td>193.660</td>\n",
       "      <td>0.025434</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.083414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100006</td>\n",
       "      <td>148.754</td>\n",
       "      <td>28.862</td>\n",
       "      <td>107.782</td>\n",
       "      <td>106.130</td>\n",
       "      <td>0.733</td>\n",
       "      <td>158.359</td>\n",
       "      <td>0.113</td>\n",
       "      <td>2.941</td>\n",
       "      <td>2.545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.450</td>\n",
       "      <td>56.867</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>179.877</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100007</td>\n",
       "      <td>154.916</td>\n",
       "      <td>10.418</td>\n",
       "      <td>94.714</td>\n",
       "      <td>29.169</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.897</td>\n",
       "      <td>1.526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-1.724</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>30.638</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.018636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100008</td>\n",
       "      <td>105.594</td>\n",
       "      <td>50.559</td>\n",
       "      <td>100.989</td>\n",
       "      <td>4.288</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.904</td>\n",
       "      <td>4.288</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.614803</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.296003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100009</td>\n",
       "      <td>128.053</td>\n",
       "      <td>88.941</td>\n",
       "      <td>69.272</td>\n",
       "      <td>193.392</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.609</td>\n",
       "      <td>28.859</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>-2.514</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>167.735</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100010</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>86.240</td>\n",
       "      <td>79.692</td>\n",
       "      <td>27.201</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.338</td>\n",
       "      <td>27.201</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.701141</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.299504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100011</td>\n",
       "      <td>114.744</td>\n",
       "      <td>10.286</td>\n",
       "      <td>75.712</td>\n",
       "      <td>30.816</td>\n",
       "      <td>2.563</td>\n",
       "      <td>252.599</td>\n",
       "      <td>-1.401</td>\n",
       "      <td>2.888</td>\n",
       "      <td>36.745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>0.303</td>\n",
       "      <td>56.876</td>\n",
       "      <td>1.773</td>\n",
       "      <td>-2.079</td>\n",
       "      <td>165.640</td>\n",
       "      <td>0.093659</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.307170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100012</td>\n",
       "      <td>145.297</td>\n",
       "      <td>64.234</td>\n",
       "      <td>103.565</td>\n",
       "      <td>106.999</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.183</td>\n",
       "      <td>24.660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.970</td>\n",
       "      <td>1.943</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>93.117</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.681611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100013</td>\n",
       "      <td>82.488</td>\n",
       "      <td>31.663</td>\n",
       "      <td>64.128</td>\n",
       "      <td>8.232</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.823</td>\n",
       "      <td>8.232</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.665890</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.183892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100014</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>109.412</td>\n",
       "      <td>14.398</td>\n",
       "      <td>17.323</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.472</td>\n",
       "      <td>17.323</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.655922</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.151199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100015</td>\n",
       "      <td>111.026</td>\n",
       "      <td>32.096</td>\n",
       "      <td>75.271</td>\n",
       "      <td>23.067</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.205</td>\n",
       "      <td>23.067</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.018636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100016</td>\n",
       "      <td>114.256</td>\n",
       "      <td>4.351</td>\n",
       "      <td>67.963</td>\n",
       "      <td>47.221</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.954</td>\n",
       "      <td>26.243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>-0.686</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>36.263</td>\n",
       "      <td>0.443598</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.454848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100017</td>\n",
       "      <td>127.861</td>\n",
       "      <td>50.953</td>\n",
       "      <td>77.267</td>\n",
       "      <td>26.967</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.833</td>\n",
       "      <td>26.967</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100018</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>85.186</td>\n",
       "      <td>68.827</td>\n",
       "      <td>5.042</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.116</td>\n",
       "      <td>5.042</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.561633</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.121624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100019</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>88.767</td>\n",
       "      <td>115.058</td>\n",
       "      <td>15.337</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.879</td>\n",
       "      <td>15.337</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.823163</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.979351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100020</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>89.705</td>\n",
       "      <td>41.765</td>\n",
       "      <td>18.437</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.395</td>\n",
       "      <td>18.437</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.670373</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.198594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100021</td>\n",
       "      <td>90.736</td>\n",
       "      <td>18.674</td>\n",
       "      <td>60.231</td>\n",
       "      <td>25.156</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.363</td>\n",
       "      <td>25.156</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.681611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100022</td>\n",
       "      <td>87.075</td>\n",
       "      <td>38.217</td>\n",
       "      <td>67.041</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.852</td>\n",
       "      <td>2.347</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.393245</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>4.569368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100023</td>\n",
       "      <td>141.481</td>\n",
       "      <td>0.736</td>\n",
       "      <td>111.581</td>\n",
       "      <td>174.075</td>\n",
       "      <td>1.955</td>\n",
       "      <td>364.344</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>1.335</td>\n",
       "      <td>6.663</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156</td>\n",
       "      <td>1.416</td>\n",
       "      <td>82.477</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-2.785</td>\n",
       "      <td>278.009</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100024</td>\n",
       "      <td>110.785</td>\n",
       "      <td>72.927</td>\n",
       "      <td>82.775</td>\n",
       "      <td>30.888</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.032</td>\n",
       "      <td>30.888</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.774979</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.541666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100025</td>\n",
       "      <td>76.883</td>\n",
       "      <td>34.384</td>\n",
       "      <td>56.993</td>\n",
       "      <td>5.569</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.912</td>\n",
       "      <td>5.569</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.681611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100026</td>\n",
       "      <td>137.197</td>\n",
       "      <td>68.009</td>\n",
       "      <td>78.296</td>\n",
       "      <td>35.332</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.883</td>\n",
       "      <td>0.204</td>\n",
       "      <td>...</td>\n",
       "      <td>4.347</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>35.527</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100027</td>\n",
       "      <td>111.271</td>\n",
       "      <td>27.180</td>\n",
       "      <td>70.642</td>\n",
       "      <td>144.766</td>\n",
       "      <td>4.936</td>\n",
       "      <td>1021.322</td>\n",
       "      <td>-5.834</td>\n",
       "      <td>1.795</td>\n",
       "      <td>0.367</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.961</td>\n",
       "      <td>2.220</td>\n",
       "      <td>43.458</td>\n",
       "      <td>2.974</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>214.170</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100028</td>\n",
       "      <td>118.104</td>\n",
       "      <td>2.633</td>\n",
       "      <td>77.310</td>\n",
       "      <td>91.388</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.976</td>\n",
       "      <td>21.536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>1.426</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>77.221</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100029</td>\n",
       "      <td>98.761</td>\n",
       "      <td>14.024</td>\n",
       "      <td>74.230</td>\n",
       "      <td>132.806</td>\n",
       "      <td>3.676</td>\n",
       "      <td>315.854</td>\n",
       "      <td>-2.665</td>\n",
       "      <td>1.261</td>\n",
       "      <td>23.290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>32.625</td>\n",
       "      <td>-2.683</td>\n",
       "      <td>-1.467</td>\n",
       "      <td>113.252</td>\n",
       "      <td>0.094460</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.309795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818208</th>\n",
       "      <td>918208</td>\n",
       "      <td>201.622</td>\n",
       "      <td>38.204</td>\n",
       "      <td>131.375</td>\n",
       "      <td>1.017</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>4.455</td>\n",
       "      <td>1.017</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.925626</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>41.468615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818209</th>\n",
       "      <td>918209</td>\n",
       "      <td>101.034</td>\n",
       "      <td>58.485</td>\n",
       "      <td>80.316</td>\n",
       "      <td>0.149</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.724</td>\n",
       "      <td>0.149</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.385835</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>62.086275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818210</th>\n",
       "      <td>918210</td>\n",
       "      <td>136.095</td>\n",
       "      <td>49.715</td>\n",
       "      <td>102.729</td>\n",
       "      <td>6.810</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.069</td>\n",
       "      <td>6.810</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818211</th>\n",
       "      <td>918211</td>\n",
       "      <td>80.222</td>\n",
       "      <td>5.694</td>\n",
       "      <td>57.055</td>\n",
       "      <td>38.959</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.985</td>\n",
       "      <td>...</td>\n",
       "      <td>2.713</td>\n",
       "      <td>1.790</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>37.489</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>22.971060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818212</th>\n",
       "      <td>918212</td>\n",
       "      <td>143.655</td>\n",
       "      <td>106.016</td>\n",
       "      <td>113.078</td>\n",
       "      <td>13.279</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.497</td>\n",
       "      <td>50.204</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.867</td>\n",
       "      <td>2.433</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>52.332</td>\n",
       "      <td>0.226870</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>10.163918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818213</th>\n",
       "      <td>918213</td>\n",
       "      <td>225.431</td>\n",
       "      <td>94.018</td>\n",
       "      <td>135.646</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.594</td>\n",
       "      <td>0.123</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.909680</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>40.754236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818214</th>\n",
       "      <td>918214</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>85.725</td>\n",
       "      <td>164.017</td>\n",
       "      <td>150.189</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.105</td>\n",
       "      <td>24.241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-1.977</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>126.319</td>\n",
       "      <td>0.782818</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>35.070702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818215</th>\n",
       "      <td>918215</td>\n",
       "      <td>93.050</td>\n",
       "      <td>21.326</td>\n",
       "      <td>68.026</td>\n",
       "      <td>3.505</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.767</td>\n",
       "      <td>3.505</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818216</th>\n",
       "      <td>918216</td>\n",
       "      <td>24.995</td>\n",
       "      <td>35.732</td>\n",
       "      <td>20.797</td>\n",
       "      <td>51.803</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.699</td>\n",
       "      <td>51.803</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636427</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>28.512309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818217</th>\n",
       "      <td>918217</td>\n",
       "      <td>151.604</td>\n",
       "      <td>21.734</td>\n",
       "      <td>105.448</td>\n",
       "      <td>87.754</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.580</td>\n",
       "      <td>47.695</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.565</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>48.125</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818218</th>\n",
       "      <td>918218</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>52.874</td>\n",
       "      <td>99.112</td>\n",
       "      <td>26.951</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.925</td>\n",
       "      <td>26.951</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.611755</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>27.407016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818219</th>\n",
       "      <td>918219</td>\n",
       "      <td>77.364</td>\n",
       "      <td>33.974</td>\n",
       "      <td>60.653</td>\n",
       "      <td>0.636</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.746</td>\n",
       "      <td>0.636</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>22.971060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818220</th>\n",
       "      <td>918220</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>77.513</td>\n",
       "      <td>36.229</td>\n",
       "      <td>1.756</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.756</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.562147</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>25.184532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818221</th>\n",
       "      <td>918221</td>\n",
       "      <td>101.483</td>\n",
       "      <td>12.234</td>\n",
       "      <td>63.279</td>\n",
       "      <td>144.481</td>\n",
       "      <td>5.222</td>\n",
       "      <td>913.469</td>\n",
       "      <td>-6.675</td>\n",
       "      <td>1.325</td>\n",
       "      <td>5.282</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.990</td>\n",
       "      <td>1.491</td>\n",
       "      <td>50.791</td>\n",
       "      <td>2.233</td>\n",
       "      <td>1.287</td>\n",
       "      <td>140.280</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818222</th>\n",
       "      <td>918222</td>\n",
       "      <td>106.082</td>\n",
       "      <td>17.146</td>\n",
       "      <td>60.347</td>\n",
       "      <td>252.677</td>\n",
       "      <td>3.899</td>\n",
       "      <td>709.003</td>\n",
       "      <td>-3.596</td>\n",
       "      <td>0.880</td>\n",
       "      <td>4.530</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.401</td>\n",
       "      <td>-2.440</td>\n",
       "      <td>53.867</td>\n",
       "      <td>1.498</td>\n",
       "      <td>-2.218</td>\n",
       "      <td>250.408</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818223</th>\n",
       "      <td>918223</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>130.745</td>\n",
       "      <td>305.346</td>\n",
       "      <td>248.884</td>\n",
       "      <td>1.069</td>\n",
       "      <td>217.075</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>3.597</td>\n",
       "      <td>44.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.357</td>\n",
       "      <td>114.553</td>\n",
       "      <td>-0.504</td>\n",
       "      <td>0.832</td>\n",
       "      <td>369.304</td>\n",
       "      <td>0.226870</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>10.163918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818224</th>\n",
       "      <td>918224</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>89.909</td>\n",
       "      <td>48.149</td>\n",
       "      <td>52.696</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.319</td>\n",
       "      <td>58.852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>-1.626</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>37.855</td>\n",
       "      <td>0.633648</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>28.387819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818225</th>\n",
       "      <td>918225</td>\n",
       "      <td>75.931</td>\n",
       "      <td>31.815</td>\n",
       "      <td>51.415</td>\n",
       "      <td>19.630</td>\n",
       "      <td>2.057</td>\n",
       "      <td>140.906</td>\n",
       "      <td>4.077</td>\n",
       "      <td>2.968</td>\n",
       "      <td>44.036</td>\n",
       "      <td>...</td>\n",
       "      <td>3.294</td>\n",
       "      <td>-0.783</td>\n",
       "      <td>37.409</td>\n",
       "      <td>1.238</td>\n",
       "      <td>1.868</td>\n",
       "      <td>90.118</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.037002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818226</th>\n",
       "      <td>918226</td>\n",
       "      <td>140.804</td>\n",
       "      <td>24.712</td>\n",
       "      <td>98.037</td>\n",
       "      <td>29.817</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.907</td>\n",
       "      <td>21.578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>38.654</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818227</th>\n",
       "      <td>918227</td>\n",
       "      <td>96.816</td>\n",
       "      <td>19.198</td>\n",
       "      <td>45.972</td>\n",
       "      <td>240.285</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.130</td>\n",
       "      <td>30.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.438</td>\n",
       "      <td>2.462</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>210.299</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818228</th>\n",
       "      <td>918228</td>\n",
       "      <td>73.840</td>\n",
       "      <td>60.332</td>\n",
       "      <td>66.765</td>\n",
       "      <td>1.454</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.377</td>\n",
       "      <td>1.454</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.433869</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>64.238228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818229</th>\n",
       "      <td>918229</td>\n",
       "      <td>161.338</td>\n",
       "      <td>82.848</td>\n",
       "      <td>101.681</td>\n",
       "      <td>76.665</td>\n",
       "      <td>2.882</td>\n",
       "      <td>273.808</td>\n",
       "      <td>-0.343</td>\n",
       "      <td>3.075</td>\n",
       "      <td>18.813</td>\n",
       "      <td>...</td>\n",
       "      <td>2.758</td>\n",
       "      <td>1.131</td>\n",
       "      <td>37.876</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-1.672</td>\n",
       "      <td>136.986</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818230</th>\n",
       "      <td>918230</td>\n",
       "      <td>81.272</td>\n",
       "      <td>77.396</td>\n",
       "      <td>57.820</td>\n",
       "      <td>138.807</td>\n",
       "      <td>2.405</td>\n",
       "      <td>349.248</td>\n",
       "      <td>-1.413</td>\n",
       "      <td>1.162</td>\n",
       "      <td>90.604</td>\n",
       "      <td>...</td>\n",
       "      <td>1.021</td>\n",
       "      <td>-1.313</td>\n",
       "      <td>53.388</td>\n",
       "      <td>-1.384</td>\n",
       "      <td>2.747</td>\n",
       "      <td>320.076</td>\n",
       "      <td>0.301427</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>13.504126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818231</th>\n",
       "      <td>918231</td>\n",
       "      <td>110.083</td>\n",
       "      <td>24.084</td>\n",
       "      <td>68.991</td>\n",
       "      <td>105.747</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.840</td>\n",
       "      <td>9.618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>-2.836</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>110.841</td>\n",
       "      <td>0.019533</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>0.875080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818232</th>\n",
       "      <td>918232</td>\n",
       "      <td>119.012</td>\n",
       "      <td>75.869</td>\n",
       "      <td>83.754</td>\n",
       "      <td>2.956</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.734</td>\n",
       "      <td>2.956</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.433121</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>64.204716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818233</th>\n",
       "      <td>918233</td>\n",
       "      <td>105.668</td>\n",
       "      <td>46.443</td>\n",
       "      <td>60.048</td>\n",
       "      <td>156.191</td>\n",
       "      <td>0.403</td>\n",
       "      <td>47.746</td>\n",
       "      <td>0.936</td>\n",
       "      <td>1.279</td>\n",
       "      <td>6.133</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>41.791</td>\n",
       "      <td>0.787</td>\n",
       "      <td>-1.090</td>\n",
       "      <td>154.056</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.259892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818234</th>\n",
       "      <td>918234</td>\n",
       "      <td>99.294</td>\n",
       "      <td>30.097</td>\n",
       "      <td>62.713</td>\n",
       "      <td>65.861</td>\n",
       "      <td>3.312</td>\n",
       "      <td>471.319</td>\n",
       "      <td>-2.611</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.889</td>\n",
       "      <td>...</td>\n",
       "      <td>1.293</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>70.158</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>2.893</td>\n",
       "      <td>178.856</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818235</th>\n",
       "      <td>918235</td>\n",
       "      <td>108.497</td>\n",
       "      <td>9.837</td>\n",
       "      <td>65.149</td>\n",
       "      <td>18.006</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.742</td>\n",
       "      <td>18.006</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.189365</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>53.284258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818236</th>\n",
       "      <td>918236</td>\n",
       "      <td>96.711</td>\n",
       "      <td>20.006</td>\n",
       "      <td>66.942</td>\n",
       "      <td>29.761</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.479</td>\n",
       "      <td>2.739</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460</td>\n",
       "      <td>2.637</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>30.863</td>\n",
       "      <td>0.512740</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>22.971060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818237</th>\n",
       "      <td>918237</td>\n",
       "      <td>92.373</td>\n",
       "      <td>80.109</td>\n",
       "      <td>77.619</td>\n",
       "      <td>3.984</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.486</td>\n",
       "      <td>3.984</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.531213</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>68.599269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818238 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  \\\n",
       "0        100000       138.470                       51.655        97.827   \n",
       "1        100001       160.937                       68.768       103.235   \n",
       "2        100002      -999.000                      162.172       125.953   \n",
       "3        100003       143.905                       81.417        80.943   \n",
       "4        100004       175.864                       16.915       134.805   \n",
       "5        100005        89.744                       13.550        59.149   \n",
       "6        100006       148.754                       28.862       107.782   \n",
       "7        100007       154.916                       10.418        94.714   \n",
       "8        100008       105.594                       50.559       100.989   \n",
       "9        100009       128.053                       88.941        69.272   \n",
       "10       100010      -999.000                       86.240        79.692   \n",
       "11       100011       114.744                       10.286        75.712   \n",
       "12       100012       145.297                       64.234       103.565   \n",
       "13       100013        82.488                       31.663        64.128   \n",
       "14       100014      -999.000                      109.412        14.398   \n",
       "15       100015       111.026                       32.096        75.271   \n",
       "16       100016       114.256                        4.351        67.963   \n",
       "17       100017       127.861                       50.953        77.267   \n",
       "18       100018      -999.000                       85.186        68.827   \n",
       "19       100019      -999.000                       88.767       115.058   \n",
       "20       100020      -999.000                       89.705        41.765   \n",
       "21       100021        90.736                       18.674        60.231   \n",
       "22       100022        87.075                       38.217        67.041   \n",
       "23       100023       141.481                        0.736       111.581   \n",
       "24       100024       110.785                       72.927        82.775   \n",
       "25       100025        76.883                       34.384        56.993   \n",
       "26       100026       137.197                       68.009        78.296   \n",
       "27       100027       111.271                       27.180        70.642   \n",
       "28       100028       118.104                        2.633        77.310   \n",
       "29       100029        98.761                       14.024        74.230   \n",
       "...         ...           ...                          ...           ...   \n",
       "818208   918208       201.622                       38.204       131.375   \n",
       "818209   918209       101.034                       58.485        80.316   \n",
       "818210   918210       136.095                       49.715       102.729   \n",
       "818211   918211        80.222                        5.694        57.055   \n",
       "818212   918212       143.655                      106.016       113.078   \n",
       "818213   918213       225.431                       94.018       135.646   \n",
       "818214   918214      -999.000                       85.725       164.017   \n",
       "818215   918215        93.050                       21.326        68.026   \n",
       "818216   918216        24.995                       35.732        20.797   \n",
       "818217   918217       151.604                       21.734       105.448   \n",
       "818218   918218      -999.000                       52.874        99.112   \n",
       "818219   918219        77.364                       33.974        60.653   \n",
       "818220   918220      -999.000                       77.513        36.229   \n",
       "818221   918221       101.483                       12.234        63.279   \n",
       "818222   918222       106.082                       17.146        60.347   \n",
       "818223   918223      -999.000                      130.745       305.346   \n",
       "818224   918224      -999.000                       89.909        48.149   \n",
       "818225   918225        75.931                       31.815        51.415   \n",
       "818226   918226       140.804                       24.712        98.037   \n",
       "818227   918227        96.816                       19.198        45.972   \n",
       "818228   918228        73.840                       60.332        66.765   \n",
       "818229   918229       161.338                       82.848       101.681   \n",
       "818230   918230        81.272                       77.396        57.820   \n",
       "818231   918231       110.083                       24.084        68.991   \n",
       "818232   918232       119.012                       75.869        83.754   \n",
       "818233   918233       105.668                       46.443        60.048   \n",
       "818234   918234        99.294                       30.097        62.713   \n",
       "818235   918235       108.497                        9.837        65.149   \n",
       "818236   918236        96.711                       20.006        66.942   \n",
       "818237   918237        92.373                       80.109        77.619   \n",
       "\n",
       "        DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0         27.980                 0.910           124.711                2.666   \n",
       "1         48.146              -999.000          -999.000             -999.000   \n",
       "2         35.635              -999.000          -999.000             -999.000   \n",
       "3          0.414              -999.000          -999.000             -999.000   \n",
       "4         16.405              -999.000          -999.000             -999.000   \n",
       "5        116.344                 2.636           284.584               -0.540   \n",
       "6        106.130                 0.733           158.359                0.113   \n",
       "7         29.169              -999.000          -999.000             -999.000   \n",
       "8          4.288              -999.000          -999.000             -999.000   \n",
       "9        193.392              -999.000          -999.000             -999.000   \n",
       "10        27.201              -999.000          -999.000             -999.000   \n",
       "11        30.816                 2.563           252.599               -1.401   \n",
       "12       106.999              -999.000          -999.000             -999.000   \n",
       "13         8.232              -999.000          -999.000             -999.000   \n",
       "14        17.323              -999.000          -999.000             -999.000   \n",
       "15        23.067              -999.000          -999.000             -999.000   \n",
       "16        47.221              -999.000          -999.000             -999.000   \n",
       "17        26.967              -999.000          -999.000             -999.000   \n",
       "18         5.042              -999.000          -999.000             -999.000   \n",
       "19        15.337              -999.000          -999.000             -999.000   \n",
       "20        18.437              -999.000          -999.000             -999.000   \n",
       "21        25.156              -999.000          -999.000             -999.000   \n",
       "22         2.347              -999.000          -999.000             -999.000   \n",
       "23       174.075                 1.955           364.344               -0.923   \n",
       "24        30.888              -999.000          -999.000             -999.000   \n",
       "25         5.569              -999.000          -999.000             -999.000   \n",
       "26        35.332              -999.000          -999.000             -999.000   \n",
       "27       144.766                 4.936          1021.322               -5.834   \n",
       "28        91.388              -999.000          -999.000             -999.000   \n",
       "29       132.806                 3.676           315.854               -2.665   \n",
       "...          ...                   ...               ...                  ...   \n",
       "818208     1.017              -999.000          -999.000             -999.000   \n",
       "818209     0.149              -999.000          -999.000             -999.000   \n",
       "818210     6.810              -999.000          -999.000             -999.000   \n",
       "818211    38.959              -999.000          -999.000             -999.000   \n",
       "818212    13.279              -999.000          -999.000             -999.000   \n",
       "818213     0.123              -999.000          -999.000             -999.000   \n",
       "818214   150.189              -999.000          -999.000             -999.000   \n",
       "818215     3.505              -999.000          -999.000             -999.000   \n",
       "818216    51.803              -999.000          -999.000             -999.000   \n",
       "818217    87.754              -999.000          -999.000             -999.000   \n",
       "818218    26.951              -999.000          -999.000             -999.000   \n",
       "818219     0.636              -999.000          -999.000             -999.000   \n",
       "818220     1.756              -999.000          -999.000             -999.000   \n",
       "818221   144.481                 5.222           913.469               -6.675   \n",
       "818222   252.677                 3.899           709.003               -3.596   \n",
       "818223   248.884                 1.069           217.075               -0.285   \n",
       "818224    52.696              -999.000          -999.000             -999.000   \n",
       "818225    19.630                 2.057           140.906                4.077   \n",
       "818226    29.817              -999.000          -999.000             -999.000   \n",
       "818227   240.285              -999.000          -999.000             -999.000   \n",
       "818228     1.454              -999.000          -999.000             -999.000   \n",
       "818229    76.665                 2.882           273.808               -0.343   \n",
       "818230   138.807                 2.405           349.248               -1.413   \n",
       "818231   105.747              -999.000          -999.000             -999.000   \n",
       "818232     2.956              -999.000          -999.000             -999.000   \n",
       "818233   156.191                 0.403            47.746                0.936   \n",
       "818234    65.861                 3.312           471.319               -2.611   \n",
       "818235    18.006              -999.000          -999.000             -999.000   \n",
       "818236    29.761              -999.000          -999.000             -999.000   \n",
       "818237     3.984              -999.000          -999.000             -999.000   \n",
       "\n",
       "        DER_deltar_tau_lep  DER_pt_tot      ...       PRI_jet_leading_eta  \\\n",
       "0                    3.064      41.928      ...                     2.150   \n",
       "1                    3.473       2.078      ...                     0.725   \n",
       "2                    3.148       9.336      ...                     2.053   \n",
       "3                    3.310       0.414      ...                  -999.000   \n",
       "4                    3.891      16.405      ...                  -999.000   \n",
       "5                    1.362      61.619      ...                    -2.412   \n",
       "6                    2.941       2.545      ...                     0.864   \n",
       "7                    2.897       1.526      ...                    -0.715   \n",
       "8                    2.904       4.288      ...                  -999.000   \n",
       "9                    1.609      28.859      ...                    -2.767   \n",
       "10                   2.338      27.201      ...                  -999.000   \n",
       "11                   2.888      36.745      ...                    -0.790   \n",
       "12                   2.183      24.660      ...                    -0.970   \n",
       "13                   2.823       8.232      ...                  -999.000   \n",
       "14                   0.472      17.323      ...                  -999.000   \n",
       "15                   3.205      23.067      ...                  -999.000   \n",
       "16                   2.954      26.243      ...                    -0.766   \n",
       "17                   2.833      26.967      ...                  -999.000   \n",
       "18                   2.116       5.042      ...                  -999.000   \n",
       "19                   2.879      15.337      ...                  -999.000   \n",
       "20                   1.395      18.437      ...                  -999.000   \n",
       "21                   2.363      25.156      ...                  -999.000   \n",
       "22                   2.852       2.347      ...                  -999.000   \n",
       "23                   1.335       6.663      ...                     1.156   \n",
       "24                   3.032      30.888      ...                  -999.000   \n",
       "25                   2.912       5.569      ...                  -999.000   \n",
       "26                   2.883       0.204      ...                     4.347   \n",
       "27                   1.795       0.367      ...                    -1.961   \n",
       "28                   1.976      21.536      ...                    -0.049   \n",
       "29                   1.261      23.290      ...                     0.993   \n",
       "...                    ...         ...      ...                       ...   \n",
       "818208               4.455       1.017      ...                  -999.000   \n",
       "818209               2.724       0.149      ...                  -999.000   \n",
       "818210               3.069       6.810      ...                  -999.000   \n",
       "818211               2.269       2.985      ...                     2.713   \n",
       "818212               2.497      50.204      ...                    -1.867   \n",
       "818213               3.594       0.123      ...                  -999.000   \n",
       "818214               3.105      24.241      ...                    -0.333   \n",
       "818215               2.767       3.505      ...                  -999.000   \n",
       "818216               0.699      51.803      ...                  -999.000   \n",
       "818217               2.580      47.695      ...                    -3.565   \n",
       "818218               2.925      26.951      ...                  -999.000   \n",
       "818219               2.746       0.636      ...                  -999.000   \n",
       "818220               1.098       1.756      ...                  -999.000   \n",
       "818221               1.325       5.282      ...                    -2.990   \n",
       "818222               0.880       4.530      ...                    -2.401   \n",
       "818223               3.597      44.572      ...                     0.566   \n",
       "818224               1.319      58.852      ...                    -0.714   \n",
       "818225               2.968      44.036      ...                     3.294   \n",
       "818226               2.907      21.578      ...                    -0.153   \n",
       "818227               1.130      30.000      ...                    -1.438   \n",
       "818228               2.377       1.454      ...                  -999.000   \n",
       "818229               3.075      18.813      ...                     2.758   \n",
       "818230               1.162      90.604      ...                     1.021   \n",
       "818231               1.840       9.618      ...                    -0.348   \n",
       "818232               2.734       2.956      ...                  -999.000   \n",
       "818233               1.279       6.133      ...                     1.190   \n",
       "818234               2.294       2.889      ...                     1.293   \n",
       "818235               2.742      18.006      ...                  -999.000   \n",
       "818236               2.479       2.739      ...                     1.460   \n",
       "818237               2.486       3.984      ...                  -999.000   \n",
       "\n",
       "        PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                     0.444                 46.062                   1.240   \n",
       "1                     1.158               -999.000                -999.000   \n",
       "2                    -2.028               -999.000                -999.000   \n",
       "3                  -999.000               -999.000                -999.000   \n",
       "4                  -999.000               -999.000                -999.000   \n",
       "5                    -0.653                 56.165                   0.224   \n",
       "6                     1.450                 56.867                   0.131   \n",
       "7                    -1.724               -999.000                -999.000   \n",
       "8                  -999.000               -999.000                -999.000   \n",
       "9                    -2.514               -999.000                -999.000   \n",
       "10                 -999.000               -999.000                -999.000   \n",
       "11                    0.303                 56.876                   1.773   \n",
       "12                    1.943               -999.000                -999.000   \n",
       "13                 -999.000               -999.000                -999.000   \n",
       "14                 -999.000               -999.000                -999.000   \n",
       "15                 -999.000               -999.000                -999.000   \n",
       "16                   -0.686               -999.000                -999.000   \n",
       "17                 -999.000               -999.000                -999.000   \n",
       "18                 -999.000               -999.000                -999.000   \n",
       "19                 -999.000               -999.000                -999.000   \n",
       "20                 -999.000               -999.000                -999.000   \n",
       "21                 -999.000               -999.000                -999.000   \n",
       "22                 -999.000               -999.000                -999.000   \n",
       "23                    1.416                 82.477                  -0.798   \n",
       "24                 -999.000               -999.000                -999.000   \n",
       "25                 -999.000               -999.000                -999.000   \n",
       "26                   -0.169               -999.000                -999.000   \n",
       "27                    2.220                 43.458                   2.974   \n",
       "28                    1.426               -999.000                -999.000   \n",
       "29                   -2.018                 32.625                  -2.683   \n",
       "...                     ...                    ...                     ...   \n",
       "818208             -999.000               -999.000                -999.000   \n",
       "818209             -999.000               -999.000                -999.000   \n",
       "818210             -999.000               -999.000                -999.000   \n",
       "818211                1.790               -999.000                -999.000   \n",
       "818212                2.433               -999.000                -999.000   \n",
       "818213             -999.000               -999.000                -999.000   \n",
       "818214               -1.977               -999.000                -999.000   \n",
       "818215             -999.000               -999.000                -999.000   \n",
       "818216             -999.000               -999.000                -999.000   \n",
       "818217                0.111               -999.000                -999.000   \n",
       "818218             -999.000               -999.000                -999.000   \n",
       "818219             -999.000               -999.000                -999.000   \n",
       "818220             -999.000               -999.000                -999.000   \n",
       "818221                1.491                 50.791                   2.233   \n",
       "818222               -2.440                 53.867                   1.498   \n",
       "818223               -0.357                114.553                  -0.504   \n",
       "818224               -1.626               -999.000                -999.000   \n",
       "818225               -0.783                 37.409                   1.238   \n",
       "818226               -0.147               -999.000                -999.000   \n",
       "818227                2.462               -999.000                -999.000   \n",
       "818228             -999.000               -999.000                -999.000   \n",
       "818229                1.131                 37.876                  -0.124   \n",
       "818230               -1.313                 53.388                  -1.384   \n",
       "818231               -2.836               -999.000                -999.000   \n",
       "818232             -999.000               -999.000                -999.000   \n",
       "818233               -0.766                 41.791                   0.787   \n",
       "818234               -0.868                 70.158                  -2.018   \n",
       "818235             -999.000               -999.000                -999.000   \n",
       "818236                2.637               -999.000                -999.000   \n",
       "818237             -999.000               -999.000                -999.000   \n",
       "\n",
       "        PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  Label  KaggleSet  \\\n",
       "0                       -2.475         113.497  0.000814      1          t   \n",
       "1                     -999.000          46.226  0.681042      0          t   \n",
       "2                     -999.000          44.251  0.715742      0          t   \n",
       "3                     -999.000          -0.000  1.660654      0          t   \n",
       "4                     -999.000           0.000  1.904263      0          t   \n",
       "5                        3.106         193.660  0.025434      0          t   \n",
       "6                       -2.767         179.877  0.000814      1          t   \n",
       "7                     -999.000          30.638  0.005721      1          t   \n",
       "8                     -999.000           0.000  1.614803      0          t   \n",
       "9                     -999.000         167.735  0.000461      1          t   \n",
       "10                    -999.000           0.000  0.701141      0          t   \n",
       "11                      -2.079         165.640  0.093659      0          t   \n",
       "12                    -999.000          93.117  0.512740      0          t   \n",
       "13                    -999.000           0.000  0.665890      0          t   \n",
       "14                    -999.000           0.000  0.655922      0          t   \n",
       "15                    -999.000          -0.000  0.005721      1          t   \n",
       "16                    -999.000          36.263  0.443598      0          t   \n",
       "17                    -999.000           0.000  0.000461      1          t   \n",
       "18                    -999.000           0.000  1.561633      0          t   \n",
       "19                    -999.000          -0.000  1.823163      0          t   \n",
       "20                    -999.000           0.000  0.670373      0          t   \n",
       "21                    -999.000           0.000  0.512740      0          t   \n",
       "22                    -999.000           0.000  1.393245      0          t   \n",
       "23                      -2.785         278.009  0.000461      1          t   \n",
       "24                    -999.000           0.000  0.774979      0          t   \n",
       "25                    -999.000          -0.000  0.512740      0          t   \n",
       "26                    -999.000          35.527  0.000461      1          t   \n",
       "27                      -0.103         214.170  0.000461      1          t   \n",
       "28                    -999.000          77.221  0.000461      1          t   \n",
       "29                      -1.467         113.252  0.094460      0          t   \n",
       "...                        ...             ...       ...    ...        ...   \n",
       "818208                -999.000           0.000  0.925626      0          u   \n",
       "818209                -999.000           0.000  1.385835      0          u   \n",
       "818210                -999.000           0.000  0.005721      1          u   \n",
       "818211                -999.000          37.489  0.512740      0          u   \n",
       "818212                -999.000          52.332  0.226870      0          u   \n",
       "818213                -999.000          -0.000  0.909680      0          u   \n",
       "818214                -999.000         126.319  0.782818      0          u   \n",
       "818215                -999.000           0.000  0.005721      1          u   \n",
       "818216                -999.000           0.000  0.636427      0          u   \n",
       "818217                -999.000          48.125  0.000461      1          u   \n",
       "818218                -999.000          -0.000  0.611755      0          u   \n",
       "818219                -999.000           0.000  0.512740      0          u   \n",
       "818220                -999.000          -0.000  0.562147      0          u   \n",
       "818221                   1.287         140.280  0.000461      1          u   \n",
       "818222                  -2.218         250.408  0.000461      1          u   \n",
       "818223                   0.832         369.304  0.226870      0          u   \n",
       "818224                -999.000          37.855  0.633648      0          u   \n",
       "818225                   1.868          90.118  0.000814      1          u   \n",
       "818226                -999.000          38.654  0.005721      1          u   \n",
       "818227                -999.000         210.299  0.005721      1          u   \n",
       "818228                -999.000           0.000  1.433869      0          u   \n",
       "818229                  -1.672         136.986  0.000461      1          u   \n",
       "818230                   2.747         320.076  0.301427      0          u   \n",
       "818231                -999.000         110.841  0.019533      0          u   \n",
       "818232                -999.000          -0.000  1.433121      0          u   \n",
       "818233                  -1.090         154.056  0.005721      1          u   \n",
       "818234                   2.893         178.856  0.000461      1          u   \n",
       "818235                -999.000          -0.000  1.189365      0          u   \n",
       "818236                -999.000          30.863  0.512740      0          u   \n",
       "818237                -999.000          -0.000  1.531213      0          u   \n",
       "\n",
       "        KaggleWeight  \n",
       "0           0.002653  \n",
       "1           2.233584  \n",
       "2           2.347389  \n",
       "3           5.446378  \n",
       "4           6.245333  \n",
       "5           0.083414  \n",
       "6           0.002653  \n",
       "7           0.018636  \n",
       "8           5.296003  \n",
       "9           0.001502  \n",
       "10          2.299504  \n",
       "11          0.307170  \n",
       "12          1.681611  \n",
       "13          2.183892  \n",
       "14          2.151199  \n",
       "15          0.018636  \n",
       "16          1.454848  \n",
       "17          0.001503  \n",
       "18          5.121624  \n",
       "19          5.979351  \n",
       "20          2.198594  \n",
       "21          1.681611  \n",
       "22          4.569368  \n",
       "23          0.001503  \n",
       "24          2.541666  \n",
       "25          1.681611  \n",
       "26          0.001503  \n",
       "27          0.001503  \n",
       "28          0.001503  \n",
       "29          0.309795  \n",
       "...              ...  \n",
       "818208     41.468615  \n",
       "818209     62.086275  \n",
       "818210      0.259892  \n",
       "818211     22.971060  \n",
       "818212     10.163918  \n",
       "818213     40.754236  \n",
       "818214     35.070702  \n",
       "818215      0.259892  \n",
       "818216     28.512309  \n",
       "818217      0.020956  \n",
       "818218     27.407016  \n",
       "818219     22.971060  \n",
       "818220     25.184532  \n",
       "818221      0.020956  \n",
       "818222      0.020956  \n",
       "818223     10.163918  \n",
       "818224     28.387819  \n",
       "818225      0.037002  \n",
       "818226      0.259892  \n",
       "818227      0.259892  \n",
       "818228     64.238228  \n",
       "818229      0.020956  \n",
       "818230     13.504126  \n",
       "818231      0.875080  \n",
       "818232     64.204716  \n",
       "818233      0.259892  \n",
       "818234      0.020956  \n",
       "818235     53.284258  \n",
       "818236     22.971060  \n",
       "818237     68.599269  \n",
       "\n",
       "[818238 rows x 35 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map y values to integers\n",
    "df['Label'] = df['Label'].map({'b':0, 's':1})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "      <th>KaggleSet</th>\n",
       "      <th>KaggleWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>...</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.681042</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.233584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>...</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "      <td>0.715742</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>2.347389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.660654</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>5.446378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.904263</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>6.245333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0   100000       138.470                       51.655        97.827    27.980   \n",
       "1   100001       160.937                       68.768       103.235    48.146   \n",
       "2   100002      -999.000                      162.172       125.953    35.635   \n",
       "3   100003       143.905                       81.417        80.943     0.414   \n",
       "4   100004       175.864                       16.915       134.805    16.405   \n",
       "\n",
       "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                  0.91           124.711                2.666   \n",
       "1               -999.00          -999.000             -999.000   \n",
       "2               -999.00          -999.000             -999.000   \n",
       "3               -999.00          -999.000             -999.000   \n",
       "4               -999.00          -999.000             -999.000   \n",
       "\n",
       "   DER_deltar_tau_lep  DER_pt_tot      ...       PRI_jet_leading_eta  \\\n",
       "0               3.064      41.928      ...                     2.150   \n",
       "1               3.473       2.078      ...                     0.725   \n",
       "2               3.148       9.336      ...                     2.053   \n",
       "3               3.310       0.414      ...                  -999.000   \n",
       "4               3.891      16.405      ...                  -999.000   \n",
       "\n",
       "   PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "0                0.444                 46.062                    1.24   \n",
       "1                1.158               -999.000                 -999.00   \n",
       "2               -2.028               -999.000                 -999.00   \n",
       "3             -999.000               -999.000                 -999.00   \n",
       "4             -999.000               -999.000                 -999.00   \n",
       "\n",
       "   PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  Label  KaggleSet  \\\n",
       "0                  -2.475         113.497  0.000814      1          t   \n",
       "1                -999.000          46.226  0.681042      0          t   \n",
       "2                -999.000          44.251  0.715742      0          t   \n",
       "3                -999.000          -0.000  1.660654      0          t   \n",
       "4                -999.000           0.000  1.904263      0          t   \n",
       "\n",
       "   KaggleWeight  \n",
       "0      0.002653  \n",
       "1      2.233584  \n",
       "2      2.347389  \n",
       "3      5.446378  \n",
       "4      6.245333  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create separate arrays\n",
    "eventID = df['EventId']\n",
    "X = df.loc[:,'DER_mass_MMC':'PRI_jet_all_pt']\n",
    "y = df['Label']\n",
    "weight = df['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now split into testing and training samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, eventID_train, event_ID_test, weight_train, weight_test = train_test_split(\n",
    "    X, y, eventID, weight, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks (MLP) in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's first look at a NN in sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.99924747\n",
      "Iteration 2, loss = 0.74596920\n",
      "Iteration 3, loss = 0.70451243\n",
      "Iteration 4, loss = 0.61863146\n",
      "Iteration 5, loss = 0.61246565\n",
      "Iteration 6, loss = 0.58735310\n",
      "Iteration 7, loss = 0.55872872\n",
      "Iteration 8, loss = 0.54823607\n",
      "Iteration 9, loss = 0.53076824\n",
      "Iteration 10, loss = 0.50875748\n",
      "Iteration 11, loss = 0.48971593\n",
      "Iteration 12, loss = 0.48518637\n",
      "Iteration 13, loss = 0.46911667\n",
      "Iteration 14, loss = 0.46353245\n",
      "Iteration 15, loss = 0.46205273\n",
      "Iteration 16, loss = 0.45421945\n",
      "Iteration 17, loss = 0.44479577\n",
      "Iteration 18, loss = 0.43524869\n",
      "Iteration 19, loss = 0.43659302\n",
      "Iteration 20, loss = 0.42953868\n",
      "Iteration 21, loss = 0.42546443\n",
      "Iteration 22, loss = 0.42183441\n",
      "Iteration 23, loss = 0.41848275\n",
      "Iteration 24, loss = 0.41585364\n",
      "Iteration 25, loss = 0.41241734\n",
      "Iteration 26, loss = 0.40869482\n",
      "Iteration 27, loss = 0.40648287\n",
      "Iteration 28, loss = 0.40533823\n",
      "Iteration 29, loss = 0.40220722\n",
      "Iteration 30, loss = 0.40217402\n",
      "Iteration 31, loss = 0.39989184\n",
      "Iteration 32, loss = 0.40025553\n",
      "Iteration 33, loss = 0.39915762\n",
      "Iteration 34, loss = 0.39791608\n",
      "Iteration 35, loss = 0.39793989\n",
      "Iteration 36, loss = 0.39703479\n",
      "Iteration 37, loss = 0.39692693\n",
      "Iteration 38, loss = 0.39629967\n",
      "Iteration 39, loss = 0.39604108\n",
      "Iteration 40, loss = 0.39502231\n",
      "Iteration 41, loss = 0.39504018\n",
      "Iteration 42, loss = 0.39521383\n",
      "Iteration 43, loss = 0.39454807\n",
      "Iteration 44, loss = 0.39397474\n",
      "Iteration 45, loss = 0.39401002\n",
      "Iteration 46, loss = 0.39381035\n",
      "Iteration 47, loss = 0.39410175\n",
      "Iteration 48, loss = 0.39320286\n",
      "Iteration 49, loss = 0.39281928\n",
      "Iteration 50, loss = 0.39285908\n",
      "Iteration 51, loss = 0.39266902\n",
      "Iteration 52, loss = 0.39269909\n",
      "Iteration 53, loss = 0.39252425\n",
      "Iteration 54, loss = 0.39231612\n",
      "Iteration 55, loss = 0.39195796\n",
      "Iteration 56, loss = 0.39160064\n",
      "Iteration 57, loss = 0.39196043\n",
      "Iteration 58, loss = 0.39091320\n",
      "Iteration 59, loss = 0.39096592\n",
      "Iteration 60, loss = 0.39127666\n",
      "Iteration 61, loss = 0.39098656\n",
      "Iteration 62, loss = 0.39085978\n",
      "Iteration 63, loss = 0.39091866\n",
      "Iteration 64, loss = 0.39051586\n",
      "Iteration 65, loss = 0.39000766\n",
      "Iteration 66, loss = 0.38958121\n",
      "Iteration 67, loss = 0.38977356\n",
      "Iteration 68, loss = 0.39060584\n",
      "Iteration 69, loss = 0.38984462\n",
      "Iteration 70, loss = 0.38946186\n",
      "Iteration 71, loss = 0.38947496\n",
      "Iteration 72, loss = 0.38943917\n",
      "Iteration 73, loss = 0.38916991\n",
      "Iteration 74, loss = 0.38934081\n",
      "Iteration 75, loss = 0.38957211\n",
      "Iteration 76, loss = 0.38845222\n",
      "Iteration 77, loss = 0.38855982\n",
      "Iteration 78, loss = 0.38839523\n",
      "Iteration 79, loss = 0.38811665\n",
      "Iteration 80, loss = 0.38880192\n",
      "Iteration 81, loss = 0.38848378\n",
      "Iteration 82, loss = 0.38858925\n",
      "Iteration 83, loss = 0.38818757\n",
      "Iteration 84, loss = 0.38821170\n",
      "Iteration 85, loss = 0.38794007\n",
      "Iteration 86, loss = 0.38838128\n",
      "Iteration 87, loss = 0.38732705\n",
      "Iteration 88, loss = 0.38824899\n",
      "Iteration 89, loss = 0.38778227\n",
      "Iteration 90, loss = 0.38776647\n",
      "Iteration 91, loss = 0.38743617\n",
      "Iteration 92, loss = 0.38747229\n",
      "Iteration 93, loss = 0.38737039\n",
      "Iteration 94, loss = 0.38743814\n",
      "Iteration 95, loss = 0.38695306\n",
      "Iteration 96, loss = 0.38727986\n",
      "Iteration 97, loss = 0.38674566\n",
      "Iteration 98, loss = 0.38685317\n",
      "Iteration 99, loss = 0.38697500\n",
      "Iteration 100, loss = 0.38720109\n",
      "Iteration 101, loss = 0.38707760\n",
      "Iteration 102, loss = 0.38703960\n",
      "Iteration 103, loss = 0.38646884\n",
      "Iteration 104, loss = 0.38640645\n",
      "Iteration 105, loss = 0.38656766\n",
      "Iteration 106, loss = 0.38717721\n",
      "Iteration 107, loss = 0.38642160\n",
      "Iteration 108, loss = 0.38626977\n",
      "Iteration 109, loss = 0.38678928\n",
      "Iteration 110, loss = 0.38692361\n",
      "Iteration 111, loss = 0.38598089\n",
      "Iteration 112, loss = 0.38627960\n",
      "Iteration 113, loss = 0.38644822\n",
      "Iteration 114, loss = 0.38603129\n",
      "Iteration 115, loss = 0.38674470\n",
      "Iteration 116, loss = 0.38634315\n",
      "Iteration 117, loss = 0.38596747\n",
      "Iteration 118, loss = 0.38644219\n",
      "Iteration 119, loss = 0.38572298\n",
      "Iteration 120, loss = 0.38622918\n",
      "Iteration 121, loss = 0.38621154\n",
      "Iteration 122, loss = 0.38606597\n",
      "Iteration 123, loss = 0.38592730\n",
      "Iteration 124, loss = 0.38613075\n",
      "Iteration 125, loss = 0.38581993\n",
      "Iteration 126, loss = 0.38587675\n",
      "Iteration 127, loss = 0.38628112\n",
      "Iteration 128, loss = 0.38568982\n",
      "Iteration 129, loss = 0.38557066\n",
      "Iteration 130, loss = 0.38616905\n",
      "Iteration 131, loss = 0.38581788\n",
      "Iteration 132, loss = 0.38562065\n",
      "Iteration 133, loss = 0.38521504\n",
      "Iteration 134, loss = 0.38546931\n",
      "Iteration 135, loss = 0.38582872\n",
      "Iteration 136, loss = 0.38532111\n",
      "Iteration 137, loss = 0.38568287\n",
      "Iteration 138, loss = 0.38501450\n",
      "Iteration 139, loss = 0.38577949\n",
      "Iteration 140, loss = 0.38524971\n",
      "Iteration 141, loss = 0.38528114\n",
      "Iteration 142, loss = 0.38552284\n",
      "Iteration 143, loss = 0.38513410\n",
      "Iteration 144, loss = 0.38531469\n",
      "Iteration 145, loss = 0.38528767\n",
      "Iteration 146, loss = 0.38495291\n",
      "Iteration 147, loss = 0.38552595\n",
      "Iteration 148, loss = 0.38503880\n",
      "Iteration 149, loss = 0.38563938\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and train\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8257159681355757"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again use the [approximate median significance][1] from the Kaggle competition to determine how good a solution was. Note that if you do not use the full data set (i.e. you split into training and testing) you have to reweigh the inputs so that the subsample yield matches to the toal yield, which we will do below.\n",
    "\n",
    "[1]: AMS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load function to compute approximate median significance (AMS)\n",
    "%pycat ams.py\n",
    "%run ams.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8221556326687097"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try a different probability cut, not the one given by default to predict().\n",
    "# We choose the top 15%, but can optimize\n",
    "y_train_prob = mlp.predict_proba(X_train)[:, 1]\n",
    "y_test_prob = mlp.predict_proba(X_test)[:, 1]\n",
    "pcut = np.percentile(y_train_prob,85)\n",
    "pcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the probability to the original data frame\n",
    "df['Prob']=mlp.predict_proba(X)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f57562b6650>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwargs = dict(histtype='stepfilled', alpha=0.3, density=True, bins=40)\n",
    "\n",
    "df[df.Label==0].Prob.hist(label='Background',**kwargs)\n",
    "df[df.Label==1].Prob.hist(label='Signal',**kwargs)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the total weights (yields)\n",
    "sigall = weight.dot(y)\n",
    "backall = weight.dot(y == 0)\n",
    "\n",
    "# The training weights\n",
    "sigtrain = weight_train.dot(y_train)\n",
    "backtrain = weight_train.dot(y_train == 0)\n",
    "\n",
    "# The training weights\n",
    "sigtest = weight_test.dot(y_test)\n",
    "backtest = weight_test.dot(y_test == 0)\n",
    "\n",
    "# aside:  these can also be done by looping instead of using a dot product\n",
    "#  (Usually vectorized operations are faster for interpreted code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at event yields that pass our selection\n",
    "sigtrain_sel = weight_train.dot(np.multiply(y_train, y_train_prob > pcut))\n",
    "backtrain_sel = weight_train.dot(np.multiply(y_train == 0, y_train_prob > pcut))\n",
    "\n",
    "sigtest_sel = weight_test.dot(np.multiply(y_test, y_test_prob > pcut))\n",
    "backtest_sel = weight_test.dot(np.multiply(y_test == 0, y_test_prob > pcut))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corrected selected yields in training sample, signal =', 251.9636594989767, ', background =', 7032.958816708725)\n",
      "('Corrected selected yields in test sample, signal =', 251.50940132139812, ', background =', 7245.1373889984)\n"
     ]
    }
   ],
   "source": [
    "# Now we need to correct the selected yields to be is if we used the full sample\n",
    "sigtrain_sel_corr = sigtrain_sel*sigall/sigtrain\n",
    "backtrain_sel_corr = backtrain_sel*backall/backtrain\n",
    "\n",
    "sigtest_sel_corr = sigtest_sel*sigall/sigtest\n",
    "backtest_sel_corr = backtest_sel*backall/backtest\n",
    "\n",
    "print(\"Corrected selected yields in training sample, signal =\", sigtrain_sel_corr, \", background =\",backtrain_sel_corr)\n",
    "print(\"Corrected selected yields in test sample, signal =\", sigtest_sel_corr, \", background =\",backtest_sel_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AMS of training sample', 2.984703267140685)\n",
      "('AMS of test sample', 2.935963543220404)\n"
     ]
    }
   ],
   "source": [
    "print(\"AMS of training sample\", ams(sigtrain_sel_corr,backtrain_sel_corr))\n",
    "print(\"AMS of test sample\", ams(sigtest_sel_corr,backtest_sel_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do? Worse than the BDT from yesterday.\n",
    "![Comparison with submissions](data/tr150908_davidRousseau_TMVAFuture_HiggsML.001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling\n",
    "Neural networks are quite sensitive to feature scaling, so let's try to scale the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'DER_mass_MMC', u'DER_mass_transverse_met_lep', u'DER_mass_vis',\n",
       "       u'DER_pt_h', u'DER_deltaeta_jet_jet', u'DER_mass_jet_jet',\n",
       "       u'DER_prodeta_jet_jet', u'DER_deltar_tau_lep', u'DER_pt_tot',\n",
       "       u'DER_sum_pt', u'DER_pt_ratio_lep_tau', u'DER_met_phi_centrality',\n",
       "       u'DER_lep_eta_centrality', u'PRI_tau_pt', u'PRI_tau_eta',\n",
       "       u'PRI_tau_phi', u'PRI_lep_pt', u'PRI_lep_eta', u'PRI_lep_phi',\n",
       "       u'PRI_met', u'PRI_met_phi', u'PRI_met_sumet', u'PRI_jet_num',\n",
       "       u'PRI_jet_leading_pt', u'PRI_jet_leading_eta', u'PRI_jet_leading_phi',\n",
       "       u'PRI_jet_subleading_pt', u'PRI_jet_subleading_eta',\n",
       "       u'PRI_jet_subleading_phi', u'PRI_jet_all_pt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5765dc4e10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.DER_mass_MMC.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=plt.hist(X_train_scaled[:,0],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.40272580\n",
      "Iteration 2, loss = 0.37932192\n",
      "Iteration 3, loss = 0.37356315\n",
      "Iteration 4, loss = 0.36959943\n",
      "Iteration 5, loss = 0.36736172\n",
      "Iteration 6, loss = 0.36573670\n",
      "Iteration 7, loss = 0.36488144\n",
      "Iteration 8, loss = 0.36404630\n",
      "Iteration 9, loss = 0.36331349\n",
      "Iteration 10, loss = 0.36294233\n",
      "Iteration 11, loss = 0.36256881\n",
      "Iteration 12, loss = 0.36226238\n",
      "Iteration 13, loss = 0.36181800\n",
      "Iteration 14, loss = 0.36142294\n",
      "Iteration 15, loss = 0.36129177\n",
      "Iteration 16, loss = 0.36109845\n",
      "Iteration 17, loss = 0.36071280\n",
      "Iteration 18, loss = 0.36070939\n",
      "Iteration 19, loss = 0.36050698\n",
      "Iteration 20, loss = 0.36022174\n",
      "Iteration 21, loss = 0.35998558\n",
      "Iteration 22, loss = 0.36006652\n",
      "Iteration 23, loss = 0.35967601\n",
      "Iteration 24, loss = 0.35975772\n",
      "Iteration 25, loss = 0.35952509\n",
      "Iteration 26, loss = 0.35926914\n",
      "Iteration 27, loss = 0.35922307\n",
      "Iteration 28, loss = 0.35915409\n",
      "Iteration 29, loss = 0.35917391\n",
      "Iteration 30, loss = 0.35898689\n",
      "Iteration 31, loss = 0.35908542\n",
      "Iteration 32, loss = 0.35870667\n",
      "Iteration 33, loss = 0.35873792\n",
      "Iteration 34, loss = 0.35856870\n",
      "Iteration 35, loss = 0.35849936\n",
      "Iteration 36, loss = 0.35847068\n",
      "Iteration 37, loss = 0.35837131\n",
      "Iteration 38, loss = 0.35834149\n",
      "Iteration 39, loss = 0.35831964\n",
      "Iteration 40, loss = 0.35804305\n",
      "Iteration 41, loss = 0.35796938\n",
      "Iteration 42, loss = 0.35776314\n",
      "Iteration 43, loss = 0.35771186\n",
      "Iteration 44, loss = 0.35780143\n",
      "Iteration 45, loss = 0.35790823\n",
      "Iteration 46, loss = 0.35777660\n",
      "Iteration 47, loss = 0.35770409\n",
      "Iteration 48, loss = 0.35762110\n",
      "Iteration 49, loss = 0.35751476\n",
      "Iteration 50, loss = 0.35756974\n",
      "Iteration 51, loss = 0.35738135\n",
      "Iteration 52, loss = 0.35735474\n",
      "Iteration 53, loss = 0.35720473\n",
      "Iteration 54, loss = 0.35728463\n",
      "Iteration 55, loss = 0.35723519\n",
      "Iteration 56, loss = 0.35704781\n",
      "Iteration 57, loss = 0.35712173\n",
      "Iteration 58, loss = 0.35693529\n",
      "Iteration 59, loss = 0.35700744\n",
      "Iteration 60, loss = 0.35686629\n",
      "Iteration 61, loss = 0.35689086\n",
      "Iteration 62, loss = 0.35667103\n",
      "Iteration 63, loss = 0.35672090\n",
      "Iteration 64, loss = 0.35688738\n",
      "Iteration 65, loss = 0.35670488\n",
      "Iteration 66, loss = 0.35674803\n",
      "Iteration 67, loss = 0.35662868\n",
      "Iteration 68, loss = 0.35661254\n",
      "Iteration 69, loss = 0.35658939\n",
      "Iteration 70, loss = 0.35646104\n",
      "Iteration 71, loss = 0.35650725\n",
      "Iteration 72, loss = 0.35659571\n",
      "Iteration 73, loss = 0.35643124\n",
      "Iteration 74, loss = 0.35644374\n",
      "Iteration 75, loss = 0.35641986\n",
      "Iteration 76, loss = 0.35645561\n",
      "Iteration 77, loss = 0.35630804\n",
      "Iteration 78, loss = 0.35634635\n",
      "Iteration 79, loss = 0.35642994\n",
      "Iteration 80, loss = 0.35631218\n",
      "Iteration 81, loss = 0.35610505\n",
      "Iteration 82, loss = 0.35620797\n",
      "Iteration 83, loss = 0.35616509\n",
      "Iteration 84, loss = 0.35599705\n",
      "Iteration 85, loss = 0.35626875\n",
      "Iteration 86, loss = 0.35617689\n",
      "Iteration 87, loss = 0.35618427\n",
      "Iteration 88, loss = 0.35599758\n",
      "Iteration 89, loss = 0.35601057\n",
      "Iteration 90, loss = 0.35608208\n",
      "Iteration 91, loss = 0.35602444\n",
      "Iteration 92, loss = 0.35599876\n",
      "Iteration 93, loss = 0.35598977\n",
      "Iteration 94, loss = 0.35598922\n",
      "Iteration 95, loss = 0.35596107\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and train a new network\n",
    "mlp_scaled = MLPClassifier(verbose=True)\n",
    "mlp_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8379225165636492"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_scaled.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different probability cut, not the one given by default to predict().\n",
    "# We choose the top 15%, but can optimize\n",
    "y_train_prob_scaled = mlp_scaled.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_prob_scaled = mlp_scaled.predict_proba(X_test_scaled)[:, 1]\n",
    "pcut_scaled = np.percentile(y_train_prob_scaled,85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at event yields that pass our selection\n",
    "sigtrain_sel_scaled = weight_train.dot(np.multiply(y_train, y_train_prob_scaled > pcut_scaled))\n",
    "backtrain_sel_scaled = weight_train.dot(np.multiply(y_train == 0, y_train_prob_scaled > pcut_scaled))\n",
    "\n",
    "sigtest_sel_scaled = weight_test.dot(np.multiply(y_test, y_test_prob_scaled > pcut_scaled))\n",
    "backtest_sel_scaled = weight_test.dot(np.multiply(y_test == 0, y_test_prob_scaled > pcut_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corrected selected yields in training sample, signal =', 240.4131079312425, ', background =', 4578.064274343947)\n",
      "('Corrected selected yields in test sample, signal =', 239.16114845849899, ', background =', 4971.4413050347985)\n"
     ]
    }
   ],
   "source": [
    "# Now we need to correct the selected yields to be is if we used the full sample\n",
    "sigtrain_sel_scaled_corr = sigtrain_sel_scaled*sigall/sigtrain\n",
    "backtrain_sel_scaled_corr = backtrain_sel_scaled*backall/backtrain\n",
    "\n",
    "sigtest_sel_scaled_corr = sigtest_sel_scaled*sigall/sigtest\n",
    "backtest_sel_scaled_corr = backtest_sel_scaled*backall/backtest\n",
    "\n",
    "print(\"Corrected selected yields in training sample, signal =\", sigtrain_sel_scaled_corr, \", background =\",backtrain_sel_scaled_corr)\n",
    "print(\"Corrected selected yields in test sample, signal =\", sigtest_sel_scaled_corr, \", background =\",backtest_sel_scaled_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AMS of training sample', 3.5189663104026203)\n",
      "('AMS of test sample', 3.361958116653685)\n"
     ]
    }
   ],
   "source": [
    "print(\"AMS of training sample\", ams(sigtrain_sel_scaled_corr,backtrain_sel_scaled_corr))\n",
    "print(\"AMS of test sample\", ams(sigtest_sel_scaled_corr,backtest_sel_scaled_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved somewhat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutral networks with Keras\n",
    "SciKit Learn has simple NNs, but if you want to do deep NNs, or train on GPUs, you probalby want to use something like Keras instead. Let's try to create a simple NN using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(30,), kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.9909186536998729, 1: 1182.31507085564}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {0: y_train.shape[0]/backtrain, 1:y_train.shape[0]/sigtrain}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "548219/548219 [==============================] - 12s 21us/step - loss: 0.3998 - acc: 0.8235\n",
      "Epoch 2/5\n",
      "548219/548219 [==============================] - 10s 18us/step - loss: 0.3828 - acc: 0.8320\n",
      "Epoch 3/5\n",
      "548219/548219 [==============================] - 10s 19us/step - loss: 0.3780 - acc: 0.8333\n",
      "Epoch 4/5\n",
      "548219/548219 [==============================] - 10s 18us/step - loss: 0.3757 - acc: 0.8343\n",
      "Epoch 5/5\n",
      "548219/548219 [==============================] - 10s 19us/step - loss: 0.3743 - acc: 0.8346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5756467090>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train_scaled, y_train, epochs=5, batch_size=128, sample_weight=weight_train)\n",
    "model.fit(X_train_scaled, y_train, epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different probability cut, not the one given by default to predict().\n",
    "# We choose the top 15%, but can optimize\n",
    "y_train_prob_keras = model.predict(X_train_scaled)[:, 0]\n",
    "y_test_prob_keras = model.predict(X_test_scaled)[:, 0]\n",
    "pcut_keras = np.percentile(y_train_prob_keras,85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78310543, 0.08843698, 0.01610034, ..., 0.19183278, 0.09180357,\n",
       "       0.01434869], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prob_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at event yields that pass our selection\n",
    "sigtrain_sel_keras = weight_train.dot(np.multiply(y_train, y_train_prob_keras > pcut_keras))\n",
    "backtrain_sel_keras = weight_train.dot(np.multiply(y_train == 0, y_train_prob_keras > pcut_keras))\n",
    "\n",
    "sigtest_sel_keras = weight_test.dot(np.multiply(y_test, y_test_prob_keras > pcut_keras))\n",
    "backtest_sel_keras = weight_test.dot(np.multiply(y_test == 0, y_test_prob_keras > pcut_keras))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corrected selected yields in training sample, signal =', 242.18985998167906, ', background =', 5027.710490980152)\n",
      "('Corrected selected yields in test sample, signal =', 240.2657955998294, ', background =', 5298.490487588569)\n"
     ]
    }
   ],
   "source": [
    "# Now we need to correct the selected yields to be is if we used the full sample\n",
    "sigtrain_sel_keras_corr = sigtrain_sel_keras*sigall/sigtrain\n",
    "backtrain_sel_keras_corr = backtrain_sel_keras*backall/backtrain\n",
    "\n",
    "sigtest_sel_keras_corr = sigtest_sel_keras*sigall/sigtest\n",
    "backtest_sel_keras_corr = backtest_sel_keras*backall/backtest\n",
    "\n",
    "print(\"Corrected selected yields in training sample, signal =\", sigtrain_sel_keras_corr, \", background =\",backtrain_sel_keras_corr)\n",
    "print(\"Corrected selected yields in test sample, signal =\", sigtest_sel_keras_corr, \", background =\",backtest_sel_keras_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AMS of training sample', 3.385431060374011)\n",
      "('AMS of test sample', 3.273246139011499)\n"
     ]
    }
   ],
   "source": [
    "print(\"AMS of training sample\", ams(sigtrain_sel_keras_corr,backtrain_sel_keras_corr))\n",
    "print(\"AMS of test sample\", ams(sigtest_sel_keras_corr,backtest_sel_keras_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only made a single layer NN in Keras. However, you can easily change the structure of the network. As an assignment, try adding an extra hidden layer and changing the number of neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things we can easily vary: number of hidden layers, the activation function, the regularization ($\\alpha$). Let's go back to MLPClassifer (scaled) and play with some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.39096249\n",
      "Iteration 2, loss = 0.37133968\n",
      "Iteration 3, loss = 0.36800982\n",
      "Iteration 4, loss = 0.36624022\n",
      "Iteration 5, loss = 0.36514912\n",
      "Iteration 6, loss = 0.36445364\n",
      "Iteration 7, loss = 0.36370807\n",
      "Iteration 8, loss = 0.36318460\n",
      "Iteration 9, loss = 0.36265512\n",
      "Iteration 10, loss = 0.36232185\n",
      "Iteration 11, loss = 0.36196902\n",
      "Iteration 12, loss = 0.36160899\n",
      "Iteration 13, loss = 0.36140230\n",
      "Iteration 14, loss = 0.36134344\n",
      "Iteration 15, loss = 0.36112840\n",
      "Iteration 16, loss = 0.36090546\n",
      "Iteration 17, loss = 0.36067543\n",
      "Iteration 18, loss = 0.36049588\n",
      "Iteration 19, loss = 0.36048507\n",
      "Iteration 20, loss = 0.36038929\n",
      "Iteration 21, loss = 0.36016239\n",
      "Iteration 22, loss = 0.36018317\n",
      "Iteration 23, loss = 0.36006408\n",
      "Iteration 24, loss = 0.35998173\n",
      "Iteration 25, loss = 0.36003014\n",
      "Iteration 26, loss = 0.35982232\n",
      "Iteration 27, loss = 0.35983919\n",
      "Iteration 28, loss = 0.35978657\n",
      "Iteration 29, loss = 0.35958220\n",
      "Iteration 30, loss = 0.35959033\n",
      "Iteration 31, loss = 0.35961342\n",
      "Iteration 32, loss = 0.35942616\n",
      "Iteration 33, loss = 0.35935238\n",
      "Iteration 34, loss = 0.35946914\n",
      "Iteration 35, loss = 0.35943912\n",
      "Iteration 36, loss = 0.35936033\n",
      "Iteration 37, loss = 0.35930129\n",
      "Iteration 38, loss = 0.35920362\n",
      "Iteration 39, loss = 0.35913928\n",
      "Iteration 40, loss = 0.35920315\n",
      "Iteration 41, loss = 0.35910783\n",
      "Iteration 42, loss = 0.35906935\n",
      "Iteration 43, loss = 0.35917854\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_play = MLPClassifier(activation='relu', hidden_layer_sizes=(100,100), alpha=0.01, verbose=True)\n",
    "mlp_play.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8371559038438036"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_play.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different probability cut, not the one given by default to predict().\n",
    "# We choose the top 15%, but can optimize\n",
    "y_train_prob_play = mlp_play.predict_proba(X_train_scaled)[:, 1]\n",
    "y_test_prob_play = mlp_play.predict_proba(X_test_scaled)[:, 1]\n",
    "pcut_play = np.percentile(y_train_prob_scaled,85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at event yields that pass our selection\n",
    "sigtrain_sel_play = weight_train.dot(np.multiply(y_train, y_train_prob_play > pcut_play))\n",
    "backtrain_sel_play = weight_train.dot(np.multiply(y_train == 0, y_train_prob_play > pcut_play))\n",
    "\n",
    "sigtest_sel_play = weight_test.dot(np.multiply(y_test, y_test_prob_play > pcut_play))\n",
    "backtest_sel_play = weight_test.dot(np.multiply(y_test == 0, y_test_prob_play > pcut_play))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Corrected selected yields in training sample, signal =', 180.55578055288962, ', background =', 2467.000016358353)\n",
      "('Corrected selected yields in test sample, signal =', 180.13992838589002, ', background =', 2741.9766162978685)\n"
     ]
    }
   ],
   "source": [
    "# Now we need to correct the selected yields to be is if we used the full sample\n",
    "sigtrain_sel_play_corr = sigtrain_sel_play*sigall/sigtrain\n",
    "backtrain_sel_play_corr = backtrain_sel_play*backall/backtrain\n",
    "\n",
    "sigtest_sel_play_corr = sigtest_sel_play*sigall/sigtest\n",
    "backtest_sel_play_corr = backtest_sel_play*backall/backtest\n",
    "\n",
    "print(\"Corrected selected yields in training sample, signal =\", sigtrain_sel_play_corr, \", background =\",backtrain_sel_play_corr)\n",
    "print(\"Corrected selected yields in test sample, signal =\", sigtest_sel_play_corr, \", background =\",backtest_sel_play_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AMS of training sample', 3.585055243644966)\n",
      "('AMS of test sample', 3.3974231077123065)\n"
     ]
    }
   ],
   "source": [
    "print(\"AMS of training sample\", ams(sigtrain_sel_play_corr,backtrain_sel_play_corr))\n",
    "print(\"AMS of test sample\", ams(sigtest_sel_play_corr,backtest_sel_play_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your tasks\n",
    "Problems (can do with either MLPClassifier or Keras):\n",
    "1. Vary the structure of the tree (number of hidden layers, number of neurons)\n",
    "1. Vary the activation. (In Keras can do it per layer, in MLPClassifier only for all)\n",
    "1. Vary the regularization. May have to do this as the structure changes.\n",
    "1. Try using derivied variables only or primary variables only.\n",
    "1. Missing data is represented by -999 before scaling. Is there a better value to use in the training?\n",
    "1. Try using the event weights to better match the background and signal shapes in the training. Note, though, that you should still treat background and signal separately; don't scale the signal down by the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
